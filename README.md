## ğŸ“‹ DescriÃ§Ã£o

Este projeto implementa e compara diferentes estratÃ©gias de aprendizado contÃ­nuo:

- **FT (Fine-Tuning)**: Treinamento sequencial sem mitigaÃ§Ã£o de esquecimento
- **ER (Experience Replay)**: Replay de amostras antigas durante o treinamento
- **OURS (AKD)**: MÃ©todo proposto com Attention Knowledge Distillation
- **JT (Joint Training)**: Upper bound - treinamento com todos os dados

### MÃ©tricas Avaliadas

- **AACC**: Average Accuracy (mÃ©dia das acurÃ¡cias finais)
- **BWT**: Backward Transfer (mede o esquecimento catastrÃ³fico)
- **IM**: Intransigence Measure (diferenÃ§a para o upper bound)

## ğŸš€ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/jmendes-victor/VisaoComputacional
cd VisaoComputacional
```

### 2. Crie um ambiente virtual (recomendado)

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

## ğŸ“ Estrutura do Projeto

```
.
â”œâ”€â”€ main.py                 # Script principal
â”œâ”€â”€ requirements.txt        # DependÃªncias
â”œâ”€â”€ README.md              # Este arquivo
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py          # ConfiguraÃ§Ãµes e hiperparÃ¢metros
â”‚   â”œâ”€â”€ utils.py           # FunÃ§Ãµes utilitÃ¡rias
â”‚   â”œâ”€â”€ dataset.py         # Dataset e DataLoader
â”‚   â”œâ”€â”€ model.py           # Arquitetura CLAM-SB
â”‚   â”œâ”€â”€ memory.py          # Buffer de replay
â”‚   â”œâ”€â”€ losses.py          # FunÃ§Ãµes de perda (KD, AKD)
â”‚   â”œâ”€â”€ trainer.py         # Engine de treinamento
â”‚   â””â”€â”€ joint_trainer.py   # Joint Training
â””â”€â”€ local_data/
    â”œâ”€â”€ csv/
    â”‚   â””â”€â”€ sce_E3/        # Arquivos CSV das tarefas
    â””â”€â”€ embeddings/        # Embeddings prÃ©-computados (.npy)
```

## ğŸ“Š Dados

Os dados consistem em embeddings prÃ©-computados de WSIs. A estrutura esperada:

- **CSV**: Arquivos com colunas `Patient` (ID) e `GT` (ground truth/classe)
- **Embeddings**: Arquivos `.npy` com nome `{Patient}.npy`

### CenÃ¡rio E3 (3 tarefas)

| Tarefa | Classes | Arquivos |
|--------|---------|----------|
| 1 | 2, 4 | 2_4_train.csv, 2_4_test.csv |
| 2 | 0, 5 | 0_5_train.csv, 0_5_test.csv |
| 3 | 1, 3 | 3_1_train.csv, 3_1_test.csv |

## â–¶ï¸ ExecuÃ§Ã£o

Execute o experimento completo:

```bash
python main.py
```

O script irÃ¡:
1. Carregar os datasets das 3 tarefas
2. Treinar cada mÃ©todo sequencialmente
3. Avaliar e exibir relatÃ³rio comparativo

### SaÃ­da Esperada

```
===================================================================================================================
                               RELATÃ“RIO DE REPRODUÃ‡ÃƒO - COMPARAÃ‡ÃƒO COM O ARTIGO                                   
===================================================================================================================
MÃ‰TODO          | MEU AACC   | PAPER      | MEU BWT    | PAPER      | MEU IM     | PAPER     
-------------------------------------------------------------------------------------------------------------------
Fine-Tuning     | 0.XXXX     | 0.3167     | -0.XXXX    | -0.8701    | -0.XXXX    | -0.1942   
ER (Replay)     | 0.XXXX     | 0.5388     | -0.XXXX    | -0.3869    | -0.XXXX    | -0.0942   
Ours (AKD)      | 0.XXXX     | 0.5926     | -0.XXXX    | -0.4056    | -0.XXXX    | -0.1604   
-------------------------------------------------------------------------------------------------------------------
Joint Training  | 0.XXXX     | 0.7311     | N/A        | N/A        | N/A        | N/A       
===================================================================================================================
```

## âš™ï¸ ConfiguraÃ§Ãµes

Os hiperparÃ¢metros podem ser ajustados em `src/config.py`:

| ParÃ¢metro | Valor | DescriÃ§Ã£o |
|-----------|-------|-----------|
| `SEED` | 42 | Seed para reprodutibilidade |
| `NUM_CLASSES` | 6 | NÃºmero total de classes |
| `DIM_FEATURES` | 512 | DimensÃ£o dos embeddings |
| `BUFFER_SIZE` | 42 | Tamanho do buffer de replay |
| `AKD_LAMBDA` | 1.0 | Peso da perda AKD |
| `KD_LAMBDA` | 1.0 | Peso da perda KD |

## ğŸ”¬ Detalhes TÃ©cnicos

### Modelo CLAM-SB

O modelo usa atenÃ§Ã£o com gate para agregar instÃ¢ncias:

1. **Feature Extraction**: Linear + ReLU + Dropout
2. **Gated Attention**: Mecanismo de atenÃ§Ã£o para ponderar instÃ¢ncias
3. **Classification**: Camada linear para prediÃ§Ã£o

### Knowledge Distillation

- **KD Loss**: KL-divergence entre logits do estudante e professor
- **AKD Loss**: KL-divergence entre distribuiÃ§Ãµes de atenÃ§Ã£o

## ğŸ“ LicenÃ§a

Este projeto Ã© para fins educacionais.

## ğŸ“š ReferÃªncias

- CLAM: Data Efficient and Weakly Supervised Computational Pathology
- Continual Learning for Medical Image Analysis
